{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "79h028ukVAnj"
      ],
      "authorship_tag": "ABX9TyOP5BU3QPcUR3vX2qhXn5lH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nseon1/badads/blob/main/badads.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step one: Load all the data.\n",
        "ads,pages,dependencies,etc\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qi87IdmmHCYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install loguru pillow\n",
        "!pip install selenium\n",
        "!pip install selenium webdriver-manager\n",
        "!apt-get update\n",
        "!apt-get install -y chromium-browser\n",
        "!pip install pillow\n",
        "!apt-get install -y chromium-browser chromium-chromedriver"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bkp8n5aFvV8f",
        "outputId": "71602bc1-ad72-4342-85d2-b1a5ed764489"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting loguru\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: loguru\n",
            "Successfully installed loguru-0.7.3\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.29.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.29.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.1.31)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (25.1.0)\n",
            "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Downloading selenium-4.29.0-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.29.0-py3-none-any.whl (492 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.9/492.9 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Installing collected packages: sortedcontainers, wsproto, outcome, trio, trio-websocket, selenium\n",
            "Successfully installed outcome-1.3.0.post0 selenium-4.29.0 sortedcontainers-2.4.0 trio-0.29.0 trio-websocket-0.12.2 wsproto-1.2.0\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (4.29.0)\n",
            "Collecting webdriver-manager\n",
            "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.29.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.1.31)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (2.32.3)\n",
            "Collecting python-dotenv (from webdriver-manager)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (24.2)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (25.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->webdriver-manager) (3.4.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv, webdriver-manager\n",
            "Successfully installed python-dotenv-1.0.1 webdriver-manager-4.0.2\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,318 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,660 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,699 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,637 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,235 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,657 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,799 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,531 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,941 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Fetched 28.9 MB in 3s (8,645 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  apparmor libfuse3-3 liblzo2-2 snapd squashfs-tools systemd-hwe-hwdb udev\n",
            "Suggested packages:\n",
            "  apparmor-profiles-extra apparmor-utils fuse3 zenity | kdialog\n",
            "The following NEW packages will be installed:\n",
            "  apparmor chromium-browser libfuse3-3 liblzo2-2 snapd squashfs-tools systemd-hwe-hwdb udev\n",
            "0 upgraded, 8 newly installed, 0 to remove and 28 not upgraded.\n",
            "Need to get 30.1 MB of archives.\n",
            "After this operation, 123 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 apparmor amd64 3.0.4-2ubuntu2.4 [598 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblzo2-2 amd64 2.10-2build3 [53.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 squashfs-tools amd64 1:4.5-3build1 [159 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.12 [1,557 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfuse3-3 amd64 3.10.5-1build1 [81.2 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 snapd amd64 2.66.1+22.04 [27.6 MB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-browser amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [49.2 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\n",
            "Fetched 30.1 MB in 1s (41.7 MB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package apparmor.\n",
            "(Reading database ... 124935 files and directories currently installed.)\n",
            "Preparing to unpack .../0-apparmor_3.0.4-2ubuntu2.4_amd64.deb ...\n",
            "Unpacking apparmor (3.0.4-2ubuntu2.4) ...\n",
            "Selecting previously unselected package liblzo2-2:amd64.\n",
            "Preparing to unpack .../1-liblzo2-2_2.10-2build3_amd64.deb ...\n",
            "Unpacking liblzo2-2:amd64 (2.10-2build3) ...\n",
            "Selecting previously unselected package squashfs-tools.\n",
            "Preparing to unpack .../2-squashfs-tools_1%3a4.5-3build1_amd64.deb ...\n",
            "Unpacking squashfs-tools (1:4.5-3build1) ...\n",
            "Selecting previously unselected package udev.\n",
            "Preparing to unpack .../3-udev_249.11-0ubuntu3.12_amd64.deb ...\n",
            "Unpacking udev (249.11-0ubuntu3.12) ...\n",
            "Selecting previously unselected package libfuse3-3:amd64.\n",
            "Preparing to unpack .../4-libfuse3-3_3.10.5-1build1_amd64.deb ...\n",
            "Unpacking libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Selecting previously unselected package snapd.\n",
            "Preparing to unpack .../5-snapd_2.66.1+22.04_amd64.deb ...\n",
            "Unpacking snapd (2.66.1+22.04) ...\n",
            "Setting up apparmor (3.0.4-2ubuntu2.4) ...\n",
            "Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service → /lib/systemd/system/apparmor.service.\n",
            "Setting up liblzo2-2:amd64 (2.10-2build3) ...\n",
            "Setting up squashfs-tools (1:4.5-3build1) ...\n",
            "Setting up udev (249.11-0ubuntu3.12) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Setting up snapd (2.66.1+22.04) ...\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service → /lib/systemd/system/snapd.apparmor.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service → /lib/systemd/system/snapd.autoimport.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service → /lib/systemd/system/snapd.core-fixup.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service → /lib/systemd/system/snapd.recovery-chooser-trigger.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Created symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Unit /lib/systemd/system/snapd.seeded.service is added as a dependency to a non-existent unit cloud-final.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.service → /lib/systemd/system/snapd.service.\n",
            "Created symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer → /lib/systemd/system/snapd.snap-repair.timer.\n",
            "Created symlink /etc/systemd/system/sockets.target.wants/snapd.socket → /lib/systemd/system/snapd.socket.\n",
            "Created symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service → /lib/systemd/system/snapd.system-shutdown.service.\n",
            "Selecting previously unselected package chromium-browser.\n",
            "(Reading database ... 125372 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-browser_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "=> Installing the chromium snap\n",
            "==> Checking connectivity with the snap store\n",
            "===> System doesn't have a working snapd, skipping\n",
            "Unpacking chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package systemd-hwe-hwdb.\n",
            "Preparing to unpack .../systemd-hwe-hwdb_249.11.5_all.deb ...\n",
            "Unpacking systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n",
            "Processing triggers for udev (249.11-0ubuntu3.12) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "chromium-browser is already the newest version (1:85.0.4183.83-0ubuntu2.22.04.1).\n",
            "The following NEW packages will be installed:\n",
            "  chromium-chromedriver\n",
            "0 upgraded, 1 newly installed, 0 to remove and 28 not upgraded.\n",
            "Need to get 2,308 B of archives.\n",
            "After this operation, 77.8 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-chromedriver amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [2,308 B]\n",
            "Fetched 2,308 B in 0s (30.7 kB/s)\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "(Reading database ... 125393 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-chromedriver_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Setting up chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "blog_folder = '/content/blog'  # Adjust this path based on where your files are\n",
        "html_files = []\n",
        "\n",
        "# Loop through the blog folder and load all HTML files\n",
        "for filename in os.listdir(blog_folder):\n",
        "    if filename.endswith(\".html\"):  # Make sure it’s an HTML file\n",
        "        file_path = os.path.join(blog_folder, filename)\n",
        "        with open(file_path, 'r') as file:\n",
        "            html_content = file.read()\n",
        "            html_files.append((filename, html_content))  # Store filenames and their content\n",
        "\n",
        "# Preview the first few HTML files to ensure they loaded correctly\n",
        "for filename, content in html_files[:3]:  # Preview first 3 files\n",
        "    print(f\"Preview of {filename}:\")\n",
        "    print(content[:300])  # Print the first 300 characters of the file\n"
      ],
      "metadata": {
        "id": "sxbBZ3F5UA9a"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "horizontal_ads_folder = '/content/horizontal'  # Adjust path\n",
        "vertical_ads_folder = '/content/vertical'  # Adjust path\n",
        "\n",
        "horizontal_ads = [os.path.join(horizontal_ads_folder, f) for f in os.listdir(horizontal_ads_folder) if f.endswith(\".png\")]\n",
        "vertical_ads = [os.path.join(vertical_ads_folder, f) for f in os.listdir(vertical_ads_folder) if f.endswith(\".png\")]\n",
        "\n",
        "# Check first few ads in each folder\n",
        "print(\"Horizontal Ads:\", horizontal_ads[:3])\n",
        "print(\"Vertical Ads:\", vertical_ads[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "VfsuenSBUHrO",
        "outputId": "ba73554f-8c7e-4678-9818-fab1e8e04090"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/horizontal'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6d0965d5f2dc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvertical_ads_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/vertical'\u001b[0m  \u001b[0;31m# Adjust path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhorizontal_ads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhorizontal_ads_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhorizontal_ads_folder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mvertical_ads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvertical_ads_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvertical_ads_folder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/horizontal'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#step two: resize any ads that are too big or too small\n",
        "\n",
        "update the sizes of all the ads\n",
        "**this replaces the original images. Careful!**"
      ],
      "metadata": {
        "id": "79h028ukVAnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for vertical\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Configuration\n",
        "image_dir = '/content/vertical'\n",
        "max_width = 250\n",
        "max_height = 1000\n",
        "valid_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp']\n",
        "\n",
        "# Track results\n",
        "resized_files = []\n",
        "compliant_files = []\n",
        "error_files = []\n",
        "\n",
        "for filename in os.listdir(image_dir):\n",
        "    file_path = os.path.join(image_dir, filename)\n",
        "\n",
        "    # Skip non-image files/directories\n",
        "    if not os.path.isfile(file_path):\n",
        "        continue\n",
        "    if os.path.splitext(filename)[1].lower() not in valid_extensions:\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            width, height = img.size\n",
        "\n",
        "            # Check if compliant\n",
        "            if width <= max_width and height <= max_height:\n",
        "                compliant_files.append((filename, width, height))\n",
        "                continue\n",
        "\n",
        "            # Calculate new dimensions while preserving aspect ratio\n",
        "            ratio = min(max_width/width, max_height/height)\n",
        "            new_width = int(width * ratio)\n",
        "            new_height = int(height * ratio)\n",
        "\n",
        "            # Resize and overwrite\n",
        "            resized_img = img.resize((new_width, new_height), Image.LANCZOS)\n",
        "            resized_img.save(file_path, optimize=True, quality=85)\n",
        "            resized_files.append((filename, (width, height), (new_width, new_height)))\n",
        "\n",
        "    except Exception as e:\n",
        "        error_files.append((filename, str(e)))\n",
        "\n",
        "# Print report\n",
        "print(\"=== Resizing Results ===\")\n",
        "print(f\"Total images: {len(resized_files) + len(compliant_files)}\")\n",
        "print(f\"Resized images: {len(resized_files)}\")\n",
        "print(f\"Already compliant: {len(compliant_files)}\")\n",
        "print(f\"Errors: {len(error_files)}\\n\")\n",
        "\n",
        "if resized_files:\n",
        "    print(\"Resized Images:\")\n",
        "    for entry in resized_files:\n",
        "        print(f\"- {entry[0]}: {entry[1][0]}x{entry[1][1]} → {entry[2][0]}x{entry[2][1]}\")\n",
        "\n",
        "if compliant_files:\n",
        "    print(\"\\nCompliant Images:\")\n",
        "    for entry in compliant_files:\n",
        "        print(f\"- {entry[0]}: {entry[1]}x{entry[2]}\")\n",
        "\n",
        "if error_files:\n",
        "    print(\"\\nErrors:\")\n",
        "    for entry in error_files:\n",
        "        print(f\"- {entry[0]}: {entry[1]}\")"
      ],
      "metadata": {
        "id": "yQBrqsHOX65t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for horizontal\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Horizontal ads configuration\n",
        "image_dir = '/content/horizontal'  # Changed to horizontal directory\n",
        "max_width = 1000                   # Max horizontal width\n",
        "max_height = 120                   # Max horizontal height\n",
        "valid_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp']\n",
        "\n",
        "# Tracking lists\n",
        "resized_files = []\n",
        "compliant_files = []\n",
        "error_files = []\n",
        "\n",
        "for filename in os.listdir(image_dir):\n",
        "    file_path = os.path.join(image_dir, filename)\n",
        "\n",
        "    # Skip non-image files and directories\n",
        "    if not os.path.isfile(file_path):\n",
        "        continue\n",
        "    if os.path.splitext(filename)[1].lower() not in valid_extensions:\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            width, height = img.size\n",
        "\n",
        "            # Check compliance\n",
        "            if width <= max_width and height <= max_height:\n",
        "                compliant_files.append((filename, width, height))\n",
        "                continue\n",
        "\n",
        "            # Calculate proportional scaling\n",
        "            width_ratio = max_width / width\n",
        "            height_ratio = max_height / height\n",
        "            scale_factor = min(width_ratio, height_ratio)\n",
        "\n",
        "            new_width = int(width * scale_factor)\n",
        "            new_height = int(height * scale_factor)\n",
        "\n",
        "            # Resize and overwrite original\n",
        "            resized_img = img.resize((new_width, new_height), Image.LANCZOS)\n",
        "            resized_img.save(file_path, optimize=True, quality=85)\n",
        "            resized_files.append((filename, (width, height), (new_width, new_height)))\n",
        "\n",
        "    except Exception as e:\n",
        "        error_files.append((filename, str(e)))\n",
        "\n",
        "# Generate report\n",
        "print(\"=== Horizontal Resizing Results ===\")\n",
        "print(f\"Total images processed: {len(resized_files) + len(compliant_files)}\")\n",
        "print(f\"Resized images: {len(resized_files)}\")\n",
        "print(f\"Already compliant: {len(compliant_files)}\")\n",
        "print(f\"Errors: {len(error_files)}\\n\")\n",
        "\n",
        "if resized_files:\n",
        "    print(\"Resized Horizontal Ads:\")\n",
        "    for entry in resized_files:\n",
        "        print(f\"• {entry[0]:<20} {entry[1][0]}x{entry[1][1]:<10} → {entry[2][0]}x{entry[2][1]}\")\n",
        "\n",
        "if compliant_files:\n",
        "    print(\"\\nCompliant Horizontal Ads:\")\n",
        "    for entry in compliant_files:\n",
        "        print(f\"• {entry[0]:<20} {entry[1]}x{entry[2]}\")\n",
        "\n",
        "if error_files:\n",
        "    print(\"\\nError Files:\")\n",
        "    for entry in error_files:\n",
        "        print(f\"• {entry[0]:<20} {entry[1]}\")"
      ],
      "metadata": {
        "id": "Jab69Zr8V3cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#step three:  add the numbers into the real login class + log it into a json/csv file.\n",
        "\n",
        "this checks a class i put into all the login buttons.\n",
        "\n",
        "#remember to only do this once!\n",
        "\n",
        "Ads are added later with numbers near them via image shenanigans because the ads lose a lot of quality when added now\n",
        "\n",
        "if this isnt working you might need to upload the folders exactly how it is in the code ; all 25 split into the main folders\n"
      ],
      "metadata": {
        "id": "jJBRbRiAVEdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import csv\n",
        "import random\n",
        "import re\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "def setup_logger():\n",
        "    \"\"\"Configure the logger for the application.\"\"\"\n",
        "    logging.basicConfig(\n",
        "        filename=\"benchmark_preparation.log\",\n",
        "        level=logging.INFO,\n",
        "        format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
        "        datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
        "    )\n",
        "    # Also log to console\n",
        "    console = logging.StreamHandler()\n",
        "    console.setLevel(logging.INFO)\n",
        "    console.setFormatter(logging.Formatter(\"%(asctime)s | %(levelname)s | %(message)s\"))\n",
        "    logging.getLogger(\"\").addHandler(console)\n",
        "\n",
        "\n",
        "def process_html_file(file_path, number):\n",
        "    \"\"\"\n",
        "    Process a single HTML file by adding a number marker box near the real-login class.\n",
        "\n",
        "    Args:\n",
        "        file_path: Path to the HTML file\n",
        "        number: The number to add near the real-login element\n",
        "\n",
        "    Returns:\n",
        "        tuple: (bool, str) Success status and element details if found\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            content = file.read()\n",
        "\n",
        "        # Parse the HTML\n",
        "        soup = BeautifulSoup(content, 'html.parser')\n",
        "\n",
        "        # Find the element with class 'real-login'\n",
        "        login_element = soup.find(class_='real-login')\n",
        "\n",
        "        if not login_element:\n",
        "            logging.warning(f\"No 'real-login' class found in {file_path}\")\n",
        "            return False, \"\"\n",
        "\n",
        "        # Create a new div element with the number in a visible box\n",
        "        number_box = soup.new_tag('div')\n",
        "        number_box['class'] = ['login-marker-box']\n",
        "        number_box['style'] = '''\n",
        "            display: inline-block;\n",
        "            width: 50px;\n",
        "            height: 50px;\n",
        "            line-height: 50px;\n",
        "            text-align: center;\n",
        "            background-color: #ffffff;\n",
        "            color: #000000;\n",
        "            font-size: 32px;\n",
        "            font-weight: bold;\n",
        "            border: 2px solid #000000;\n",
        "            border-radius: 5px;\n",
        "            margin: 5px;\n",
        "            box-shadow: 0 0 5px rgba(0,0,0,0.5);\n",
        "            position: relative;\n",
        "            z-index: 9999;\n",
        "            font-family: Arial, sans-serif;\n",
        "        '''\n",
        "        number_box.string = str(number)\n",
        "\n",
        "        # Insert the number box after the login element\n",
        "        login_element.insert_after(number_box)\n",
        "\n",
        "        # Save the modified HTML\n",
        "        with open(file_path, 'w', encoding='utf-8') as file:\n",
        "            file.write(str(soup))\n",
        "\n",
        "        element_info = {\n",
        "            \"element_type\": login_element.name,\n",
        "            \"element_id\": login_element.get('id', ''),\n",
        "            \"class_list\": login_element.get('class', []),\n",
        "            \"text_content\": login_element.get_text(strip=True)[:50] if login_element.get_text() else \"\"\n",
        "        }\n",
        "\n",
        "        logging.info(f\"Added number box {number} to {file_path}\")\n",
        "        return True, element_info\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error processing {file_path}: {e}\")\n",
        "        return False, \"\"\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function that processes all HTML files and creates mapping files in CSV and JSON.\n",
        "    \"\"\"\n",
        "    setup_logger()\n",
        "\n",
        "    # Directory containing HTML files\n",
        "    html_dir = Path(\"/content/blog\")\n",
        "\n",
        "    # Output files for the number mapping\n",
        "    mapping_txt = Path(\"/content/login_number_mapping.txt\")\n",
        "    mapping_csv = Path(\"/content/login_number_mapping.csv\")\n",
        "    mapping_json = Path(\"/content/login_number_mapping.json\")\n",
        "\n",
        "    # Get all HTML files\n",
        "    html_files = list(html_dir.glob(\"*.htm\")) + list(html_dir.glob(\"*.html\"))\n",
        "\n",
        "    if not html_files:\n",
        "        logging.error(f\"No HTML files found in {html_dir}\")\n",
        "        return\n",
        "\n",
        "    logging.info(f\"Found {len(html_files)} HTML files to process\")\n",
        "\n",
        "    # Process each file and record the mapping\n",
        "    mapping = []\n",
        "    current_number = 1  # Start with 1\n",
        "\n",
        "    for file_path in html_files:\n",
        "        success, element_info = process_html_file(file_path, current_number)\n",
        "\n",
        "        if success:\n",
        "            mapping.append({\n",
        "                \"filename\": file_path.name,\n",
        "                \"number\": current_number,\n",
        "                \"element_info\": element_info\n",
        "            })\n",
        "\n",
        "            # Update number - cycle from 1 to 9\n",
        "            current_number = current_number % 9 + 1\n",
        "\n",
        "\n",
        "    # Write the mapping to a CSV file\n",
        "    with open(mapping_csv, 'w', newline='', encoding='utf-8') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"filename\", \"number\", \"element_type\", \"element_id\", \"text_content\"])\n",
        "\n",
        "        for item in mapping:\n",
        "            writer.writerow([\n",
        "                item['filename'],\n",
        "                item['number'],\n",
        "                item['element_info']['element_type'],\n",
        "                item['element_info']['element_id'],\n",
        "                item['element_info']['text_content']\n",
        "            ])\n",
        "\n",
        "    # Write the mapping to a JSON file\n",
        "    with open(mapping_json, 'w', encoding='utf-8') as f:\n",
        "        json.dump(mapping, f, indent=2)\n",
        "\n",
        "    # Print summary of files processed\n",
        "    modified_files = [item['filename'] for item in mapping]\n",
        "    unmodified_files = [f.name for f in html_files if f.name not in modified_files]\n",
        "\n",
        "    logging.info(f\"Processed {len(mapping)} files successfully\")\n",
        "    logging.info(f\"Mapping saved to:\")\n",
        "    logging.info(f\"  - {mapping_txt}\")\n",
        "    logging.info(f\"  - {mapping_csv}\")\n",
        "    logging.info(f\"  - {mapping_json}\")\n",
        "\n",
        "    logging.info(\"\\nModified files:\")\n",
        "    for filename in modified_files:\n",
        "        logging.info(f\"  - {filename}\")\n",
        "\n",
        "    if unmodified_files:\n",
        "        logging.info(\"\\nUnmodified files (no 'real-login' elements found):\")\n",
        "        for filename in unmodified_files:\n",
        "            logging.info(f\"  - {filename}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "ZmDoAE7KyQC2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#step four: cut all the websites into screenshot size for ai/take a screenshot\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "because ai's are notoriously bad at massive images.\n",
        "This will probably give a new folder of pngs\n"
      ],
      "metadata": {
        "id": "lQSH4QXVU0Tc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt-get install -y chromium-browser chromium-chromedriver\n",
        "\n",
        "import os\n",
        "import time\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "\n",
        "\n",
        "def setup_logger():\n",
        "    \"\"\"Configure the logger for the application.\"\"\"\n",
        "    logging.basicConfig(\n",
        "        filename=\"screenshot.log\",\n",
        "        level=logging.INFO,\n",
        "        format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
        "        datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
        "    )\n",
        "    # Also log to console\n",
        "    console = logging.StreamHandler()\n",
        "    console.setLevel(logging.INFO)\n",
        "    console.setFormatter(logging.Formatter(\"%(asctime)s | %(levelname)s | %(message)s\"))\n",
        "    logging.getLogger(\"\").addHandler(console)\n",
        "\n",
        "\n",
        "def take_screenshots(html_dir, output_dir, width=1600, height=900):\n",
        "    \"\"\"\n",
        "    Take screenshots of all HTML files in the specified directory.\n",
        "\n",
        "    Args:\n",
        "        html_dir: Directory containing HTML files\n",
        "        output_dir: Directory to save screenshots\n",
        "        width: Screenshot width in pixels\n",
        "        height: Screenshot height in pixels\n",
        "    \"\"\"\n",
        "    # Set up Chrome options specifically for Chromium in Colab\n",
        "    chrome_options = Options()\n",
        "    chrome_options.add_argument(\"--headless\")\n",
        "    chrome_options.add_argument(f\"--window-size={width},{height}\")\n",
        "    chrome_options.add_argument(\"--disable-gpu\")\n",
        "    chrome_options.add_argument(\"--no-sandbox\")\n",
        "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "    # In Colab, we need to specify the chromium-browser binary location\n",
        "    chrome_options.binary_location = \"/usr/bin/chromium-browser\"\n",
        "\n",
        "    # Create output directory if it doesn't exist\n",
        "    output_dir = Path(output_dir)\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Initialize the Chrome driver with Chromium\n",
        "    # In Colab with apt-get installed chromedriver, we can use the system chromedriver\n",
        "    logging.info(\"Initializing Chromium driver...\")\n",
        "    driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "    # Set window size\n",
        "    driver.set_window_size(width, height)\n",
        "\n",
        "    # Get list of HTML files\n",
        "    html_files = list(Path(html_dir).glob(\"*.htm\")) + list(Path(html_dir).glob(\"*.html\"))\n",
        "    logging.info(f\"Found {len(html_files)} HTML files to screenshot\")\n",
        "\n",
        "    successful = []\n",
        "    failed = []\n",
        "\n",
        "    # Take screenshots of each file\n",
        "    for idx, file_path in enumerate(html_files, 1):\n",
        "        try:\n",
        "            # Convert to file URL\n",
        "            file_url = f\"file://{file_path.absolute()}\"\n",
        "            logging.info(f\"[{idx}/{len(html_files)}] Processing: {file_path.name}\")\n",
        "\n",
        "            # Navigate to the file\n",
        "            driver.get(file_url)\n",
        "\n",
        "            # Wait for page to load (adjust as needed)\n",
        "            time.sleep(1)\n",
        "\n",
        "            # Take the screenshot\n",
        "            screenshot_path = output_dir / f\"{file_path.stem}.png\"\n",
        "            driver.save_screenshot(str(screenshot_path))\n",
        "\n",
        "            logging.info(f\"Screenshot saved to: {screenshot_path}\")\n",
        "            successful.append(file_path.name)\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error taking screenshot of {file_path.name}: {e}\")\n",
        "            failed.append(file_path.name)\n",
        "\n",
        "    # Close the driver\n",
        "    driver.quit()\n",
        "\n",
        "    # Print summary\n",
        "    logging.info(f\"\\n===== SCREENSHOT SUMMARY =====\")\n",
        "    logging.info(f\"Successfully captured: {len(successful)}/{len(html_files)}\")\n",
        "    logging.info(f\"Failed: {len(failed)}/{len(html_files)}\")\n",
        "\n",
        "    if successful:\n",
        "        logging.info(f\"\\nSuccessfully captured screenshots:\")\n",
        "        for idx, filename in enumerate(successful, 1):\n",
        "            logging.info(f\"  {idx}. {filename}\")\n",
        "\n",
        "    if failed:\n",
        "        logging.info(f\"\\nFailed to capture screenshots for:\")\n",
        "        for idx, filename in enumerate(failed, 1):\n",
        "            logging.info(f\"  {idx}. {filename}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to execute the screenshot process.\"\"\"\n",
        "    setup_logger()\n",
        "\n",
        "    # Directories\n",
        "    html_dir = \"/content/blog\"\n",
        "    screenshot_dir = \"/content/screenshots\"\n",
        "\n",
        "    # Screenshot dimensions (standard 16:9 aspect ratio)\n",
        "    width = 1280\n",
        "    height = 720\n",
        "\n",
        "    logging.info(f\"Starting screenshot process at {width}x{height} resolution\")\n",
        "    take_screenshots(html_dir, screenshot_dir, width, height)\n",
        "    logging.info(\"Screenshot process completed\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "ZjkENycXV39N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step five: add all the ads into the website+ the numbers for them, as well as noting them in a spreadsheet\n",
        "\n",
        "\n",
        "you can change the starting images with starting_left/starting_right if you want different images, you can also modify the code with randomness if you want."
      ],
      "metadata": {
        "id": "S3KeqQqFVgdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import logging\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "\n",
        "def setup_logger():\n",
        "    \"\"\"Configure the logger for the application.\"\"\"\n",
        "    logging.basicConfig(\n",
        "        filename=\"ad_insertion_png.log\",\n",
        "        level=logging.INFO,\n",
        "        format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
        "        datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
        "    )\n",
        "    # Also log to console\n",
        "    console = logging.StreamHandler()\n",
        "    console.setLevel(logging.INFO)\n",
        "    console.setFormatter(logging.Formatter(\"%(asctime)s | %(levelname)s | %(message)s\"))\n",
        "    logging.getLogger(\"\").addHandler(console)\n",
        "\n",
        "\n",
        "def get_vertical_ad_files(ad_dir):\n",
        "    \"\"\"Get all vertical ad image files from the ad directory.\"\"\"\n",
        "    ad_path = Path(ad_dir)\n",
        "    return sorted(list(ad_path.glob('*.jpg')) + list(ad_path.glob('*.png')) + list(ad_path.glob('*.gif')))\n",
        "\n",
        "\n",
        "def create_number_marker(number, size=(50, 50), font_size=32):\n",
        "    \"\"\"\n",
        "    Create a number marker similar to what was used in the HTML version.\n",
        "\n",
        "    Args:\n",
        "        number: The number to display (int)\n",
        "        size: Size of the marker box (width, height)\n",
        "        font_size: Font size for the number\n",
        "\n",
        "    Returns:\n",
        "        PIL Image with the number marker\n",
        "    \"\"\"\n",
        "    # Create a new image with white background\n",
        "    marker = Image.new('RGBA', size, (255, 255, 255, 255))\n",
        "    draw = ImageDraw.Draw(marker)\n",
        "\n",
        "    # Draw border\n",
        "    border_width = 2\n",
        "    draw.rectangle(\n",
        "        [(border_width//2, border_width//2),\n",
        "         (size[0]-border_width//2-1, size[1]-border_width//2-1)],\n",
        "        outline=(0, 0, 0), width=border_width\n",
        "    )\n",
        "\n",
        "    # Add text (number)\n",
        "    try:\n",
        "        # Try to load Arial font\n",
        "        font = ImageFont.truetype(\"Arial\", font_size)\n",
        "    except IOError:\n",
        "        # If Arial is not available, use default font\n",
        "        font = ImageFont.load_default()\n",
        "\n",
        "    # Convert number to string\n",
        "    text = str(number)\n",
        "\n",
        "    # Calculate text position to center it\n",
        "    text_width = draw.textlength(text, font=font)\n",
        "    text_height = font_size  # Approximate height\n",
        "\n",
        "    text_x = (size[0] - text_width) // 2\n",
        "    text_y = (size[1] - text_height) // 2\n",
        "\n",
        "    # Draw the text\n",
        "    draw.text((text_x, text_y), text, fill=(0, 0, 0), font=font)\n",
        "\n",
        "    return marker\n",
        "\n",
        "\n",
        "def add_vertical_ads_to_screenshot(screenshot_path, output_path, left_ad_path, right_ad_path,\n",
        "                                   left_number, right_number, ad_width=160):\n",
        "    \"\"\"\n",
        "    Add vertical ads to the left and right sides of a screenshot.\n",
        "\n",
        "    Args:\n",
        "        screenshot_path: Path to the screenshot image\n",
        "        output_path: Path to save the modified image\n",
        "        left_ad_path: Path to the left ad image\n",
        "        right_ad_path: Path to the right ad image\n",
        "        left_number: Number to display on left ad\n",
        "        right_number: Number to display on right ad\n",
        "        ad_width: Width of the vertical ads in pixels\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load the screenshot\n",
        "        screenshot = Image.open(screenshot_path)\n",
        "\n",
        "        # Get dimensions\n",
        "        screen_width, screen_height = screenshot.size\n",
        "\n",
        "        # Load vertical ads\n",
        "        left_ad = Image.open(left_ad_path)\n",
        "        right_ad = Image.open(right_ad_path)\n",
        "\n",
        "        # Resize ads to specified width while maintaining aspect ratio\n",
        "        left_ad_aspect = left_ad.height / left_ad.width\n",
        "        right_ad_aspect = right_ad.height / right_ad.width\n",
        "\n",
        "        left_ad_height = int(ad_width * left_ad_aspect)\n",
        "        right_ad_height = int(ad_width * right_ad_aspect)\n",
        "\n",
        "        left_ad = left_ad.resize((ad_width, left_ad_height), Image.LANCZOS)\n",
        "        right_ad = right_ad.resize((ad_width, right_ad_height), Image.LANCZOS)\n",
        "\n",
        "        # Calculate position for vertical ads - place them in the middle vertically\n",
        "        left_y = (screen_height - left_ad_height) // 2\n",
        "        right_y = (screen_height - right_ad_height) // 2\n",
        "\n",
        "        # Create a new image with the ads\n",
        "        new_width = screen_width + (ad_width * 2)  # Original + 2 ads\n",
        "        new_height = screen_height\n",
        "\n",
        "        # Create new image with white background\n",
        "        new_image = Image.new('RGB', (new_width, new_height), (255, 255, 255))\n",
        "\n",
        "        # Paste screenshot in the middle\n",
        "        new_image.paste(screenshot, (ad_width, 0))\n",
        "\n",
        "        # Paste left ad\n",
        "        new_image.paste(left_ad, (0, left_y))\n",
        "\n",
        "        # Paste right ad\n",
        "        new_image.paste(right_ad, (ad_width + screen_width, right_y))\n",
        "\n",
        "        # Create number markers\n",
        "        left_marker = create_number_marker(left_number)\n",
        "        right_marker = create_number_marker(right_number)\n",
        "\n",
        "        # Add left marker below the ad\n",
        "        marker_x = (ad_width - left_marker.width) // 2\n",
        "        marker_y = left_y + left_ad_height + 10  # 10px padding\n",
        "\n",
        "        # If marker would go off bottom of image, place it above the ad instead\n",
        "        if marker_y + left_marker.height > new_height:\n",
        "            marker_y = left_y - left_marker.height - 10\n",
        "\n",
        "        # Paste left marker (with alpha channel)\n",
        "        new_image.paste(left_marker, (marker_x, marker_y), left_marker)\n",
        "\n",
        "        # Add right marker below the ad\n",
        "        marker_x = ad_width + screen_width + (ad_width - right_marker.width) // 2\n",
        "        marker_y = right_y + right_ad_height + 10  # 10px padding\n",
        "\n",
        "        # If marker would go off bottom of image, place it above the ad instead\n",
        "        if marker_y + right_marker.height > new_height:\n",
        "            marker_y = right_y - right_marker.height - 10\n",
        "\n",
        "        # Paste right marker (with alpha channel)\n",
        "        new_image.paste(right_marker, (marker_x, marker_y), right_marker)\n",
        "\n",
        "        # Save the result\n",
        "        new_image.save(output_path)\n",
        "        logging.info(f\"Added vertical ads to {screenshot_path.name}, saved as {output_path.name}\")\n",
        "\n",
        "        return True, {\n",
        "            \"left_ad\": left_ad_path.name,\n",
        "            \"right_ad\": right_ad_path.name,\n",
        "            \"left_number\": left_number,\n",
        "            \"right_number\": right_number\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error adding ads to {screenshot_path}: {e}\")\n",
        "        return False, {}\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function that adds vertical ads to screenshots.\n",
        "    \"\"\"\n",
        "    setup_logger()\n",
        "\n",
        "    # Directories\n",
        "    screenshots_dir = Path(\"/content/screenshots\")\n",
        "    vertical_ads_dir = Path(\"/content/vertical\")\n",
        "    output_dir = Path(\"/content/screenshots_with_ads\")\n",
        "\n",
        "    # Create output directory if it doesn't exist\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Get all screenshot files\n",
        "    screenshots = list(screenshots_dir.glob(\"*.png\"))\n",
        "\n",
        "    if not screenshots:\n",
        "        logging.error(f\"No PNG screenshots found in {screenshots_dir}\")\n",
        "        return\n",
        "\n",
        "    logging.info(f\"Found {len(screenshots)} screenshots to process\")\n",
        "\n",
        "    # Get all vertical ad files\n",
        "    vertical_ads = get_vertical_ad_files(vertical_ads_dir)\n",
        "\n",
        "    if not vertical_ads:\n",
        "        logging.error(f\"No vertical ad images found in {vertical_ads_dir}\")\n",
        "        return\n",
        "\n",
        "    logging.info(f\"Found {len(vertical_ads)} vertical ad images to use\")\n",
        "\n",
        "    # Process each screenshot\n",
        "    successful = []\n",
        "    failed = []\n",
        "    ad_mapping = []\n",
        "\n",
        "    left_ad_index = 0\n",
        "    right_ad_index = len(vertical_ads) // 2  # Start halfway through for right ads\n",
        "\n",
        "    left_number = 2  # Start with 2 for left ad\n",
        "    right_number = 6  # Start with 6 for right ad (middle of the sequence)\n",
        "\n",
        "    # Set the width for vertical ads (adjust as needed)\n",
        "    ad_width = 160  # pixels\n",
        "\n",
        "    for screenshot_path in screenshots:\n",
        "        # Get ads for this screenshot\n",
        "        left_ad_path = vertical_ads[left_ad_index]\n",
        "        right_ad_path = vertical_ads[right_ad_index]\n",
        "\n",
        "        # Output path\n",
        "        output_path = output_dir / f\"{screenshot_path.stem}_with_ads.png\"\n",
        "\n",
        "        # Add the ads to the screenshot\n",
        "        success, ad_details = add_vertical_ads_to_screenshot(\n",
        "            screenshot_path, output_path,\n",
        "            left_ad_path, right_ad_path,\n",
        "            left_number, right_number,\n",
        "            ad_width\n",
        "        )\n",
        "\n",
        "        if success:\n",
        "            successful.append(screenshot_path.name)\n",
        "            ad_mapping.append({\n",
        "                \"screenshot\": screenshot_path.name,\n",
        "                \"output\": output_path.name,\n",
        "                \"left_ad\": ad_details[\"left_ad\"],\n",
        "                \"right_ad\": ad_details[\"right_ad\"],\n",
        "                \"left_number\": ad_details[\"left_number\"],\n",
        "                \"right_number\": ad_details[\"right_number\"]\n",
        "            })\n",
        "\n",
        "            # Update ad indices - cycle through available ads\n",
        "            left_ad_index = (left_ad_index + 1) % len(vertical_ads)\n",
        "            right_ad_index = (right_ad_index + 1) % len(vertical_ads)\n",
        "\n",
        "            # Update numbers - cycle from 2-9, then 0, then back to 2 (skip 1)\n",
        "            left_number = (left_number + 1) % 10\n",
        "            if left_number == 1:\n",
        "                left_number = 2\n",
        "\n",
        "            right_number = (right_number + 1) % 10\n",
        "            if right_number == 1:\n",
        "                right_number = 2\n",
        "\n",
        "        else:\n",
        "            failed.append(screenshot_path.name)\n",
        "\n",
        "    # Print summary\n",
        "    logging.info(f\"\\n===== AD INSERTION SUMMARY =====\")\n",
        "    logging.info(f\"Successfully processed: {len(successful)}/{len(screenshots)}\")\n",
        "    logging.info(f\"Failed: {len(failed)}/{len(screenshots)}\")\n",
        "\n",
        "    if successful:\n",
        "        logging.info(f\"\\nSuccessfully processed screenshots:\")\n",
        "        for idx, filename in enumerate(successful, 1):\n",
        "            logging.info(f\"  {idx}. {filename}\")\n",
        "\n",
        "    if failed:\n",
        "        logging.info(f\"\\nFailed to process screenshots:\")\n",
        "        for idx, filename in enumerate(failed, 1):\n",
        "            logging.info(f\"  {idx}. {filename}\")\n",
        "\n",
        "    logging.info(f\"\\n=== AD INSERTION COMPLETE ===\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "kk25UyuWyoqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step seven:from here you're on your own depending on what model you're doing . Below is if you're using openai\n",
        "\n",
        "enter your openai key"
      ],
      "metadata": {
        "id": "3Bq9t-F-V80m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#port stuff here"
      ],
      "metadata": {
        "id": "qsm1zWZHWJlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step eight: Run the test"
      ],
      "metadata": {
        "id": "zJpfpY0TWKFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#port stuff here"
      ],
      "metadata": {
        "id": "KO7NsVMfWX4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#step nine: graphs,results,etc here."
      ],
      "metadata": {
        "id": "gnNJ1QeJWUoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#port stuff here"
      ],
      "metadata": {
        "id": "W0FXerHyGsS9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}